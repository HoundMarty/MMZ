## Optimální filtry ve smyslu kvadratické vzdálenosti: Adaptivní filtry

### Teoretické

[1. Adaptivní LMS filtr: definice problému, princip a odvození.](./4T1.md#adaptivní-lms)
[2. Adaptivní RLS algoritmus: princip.](./4T1.md#rls-recursive-least-square)
[3. Použití adaptivních filtrů ve frekvenční oblasti: princip.](./4T1.md#adaptivní-filtry-ve-frekvenční-oblasti)

----

Opakování z otázky [3.1 a 3.2](./3T1_2.md) 

## **Základní myšlenka**

$d[n]$ je signál, který chceme získat filtrováním signálu $x[n]$.

Chyba rozdílu je popsána následovně

$
\begin{equation}
    \begin{split}
        e[n] &= d[n] - y [n]  \\
        &= d[n] - \textbf{w}^T\textbf{x}_n
    \end{split}
\end{equation}
$

Filtr *w* můžeme hledat jako optimalizaci nějakého kritéria, např. kvadratického

$
\begin{equation}
    \begin{split}
        J_n[\textbf{w}] &= e[n]^2  \\
        &= (d[n] - \textbf{w}^T\textbf{x}_n)^2 \\
        &= d[n]^2 - 2d[n]\textbf{w}^T\textbf{x}_n + \textbf{w}^T\textbf{x}_n \textbf{x}_n^T\textbf{w}
    \end{split}
\end{equation}
$

## **Gradient $\textit{J}_n$($\textbf{w}$)**

Gradient $\textit{J}_n$($\textbf{w}$), tj. vektor parciálních derivací podle jednotlivých složek $\textbf{w}$

$
\begin{equation}
    \Delta \textit{J}_n(\textbf{w}) = -2\textbf{x}_nd(n) + 2\textbf{x}_n \textbf{x}_n^T \textbf{w}
\end{equation}
$

zavádíme označení

$
\begin{equation}
    \begin{split}
        \textbf{R}_n &= \textbf{x}_n \textbf{x}_n^T \\
        \textbf{p}_n &= \textbf{x}_n d[n]
    \end{split}
\end{equation}
$

Gradient lze zapsat také jako

$
\begin{equation}
    \Delta \textit{J}_n(\textbf{w}) = -2\textbf{p}_n + 2 \textbf{R}_n \textbf{w}
\end{equation}
$

## **Adaptivní LMS**

Cílem je průběžně- měnit filtr $w$ optimalizováním kritéria
$
\begin{equation}
    \textit{J}_n(\textbf{w}_n) = \left| d[n] - \textbf{w}_n^T\textbf{x}_n \right|^2
\end{equation}
$

LMS: metoda největšího spádu

$
\begin{equation}
    \textbf{w}_{n+1} = \textbf{w}_n - \mu \Delta \textit{J}_n(\textbf{w}_n)
\end{equation}
$
kde $\mu$ je délka kroku

Po dosazení
$
\begin{equation}
    \textbf{w}_{n+1} = \textbf{w}_n - \mu \textit{x}_n e[n]
\end{equation}
$
kde
$
\begin{equation}
    \begin{split}
        e[n] &= d[n] - y[n] \\
            &= d[n] - \textbf{w}_n^T\textbf{x}_n
    \end{split}
\end{equation}
$

Normalizovaný LMS filtr:
$
\begin{equation}
    \textbf{w}_{n+1} = \textbf{w}_n + \mu \frac{\textit{x}_n}{\left\| \textit{x}_n \right\|^2} e[n]
\end{equation}
$

## **RLS (Recursive Least Square)**

Optimalizujeme kritérium, které akumuluje chybový signál s exponenciálním zapomínáním

$
\begin{equation}
    \textit{J}_n^{RLS}(\textbf{w}_n) = \sum_{k=1}^{n} \lambda^{n-k} e_n[k]^2
\end{equation}
$
kde $0 \lt \lambda \le 1$ a chybový signál je definován jako

$
\begin{equation}
    e_n[k] = d[k] - \textbf{w}_n^T\textbf{x}_k
\end{equation}
$

Položením gradientu $\textit{J}_n^{RLS}(\textbf{w}_m)$ rovno nule dostaneme normálovou rovnici

$
\begin{equation}
    \phi_n \textbf{w}_n = \textbf{z}n
\end{equation}
$
kde $\phi_n$ je obdobou $\textbf{R}$ a $\textbf{z}_n$ je obdobou $\textbf{p}$

$
\begin{equation}
\begin{matrix}
\phi_n = \sum_{k=1}^{n} \lambda^{n-k}\textbf{x}_k \textbf{x}_k^T &  & a &  & \textbf{z}_n = \sum_{k=1}^{n} \lambda^{n-k} \textbf{x}_k d[k]
\end{matrix}
\end{equation}
$

Algoritmus je odvozený, tak abychom $(\phi_n)^{-1}$ a $\textbf{z}_n$ nemuseli v každém kroku počítat znovu. Jsou počítány rekurzivně.

Jeden krok algoritmu je počítán následovně

$
\begin{equation}
    \begin{split}
        \textbf{h}_n &= \textbf{P}_{n-1}\textbf{n}_n \\
        \textbf{k}_n &= \frac{\textbf{h}_n}{\lambda + \textbf{x}_n^T\textbf{h}_n} \\
        \xi[n] &= d[n] - \textbf{w}_{n-1}^T\textbf{x}_n \\
        \textbf{w}_n &= \textbf{w}_{n-1} + \textbf{k}_n \xi[n] \\
        \textbf{P}_n &= \lambda^{-1}\textbf{P}_{n-1} - \lambda^{-1} \textbf{k}_n \textbf{x}_n^T\textbf{P}_{n-1}
    \end{split}
\end{equation}
$

kde $\textbf{P}_n$ značí $(\phi_n)^{-1}$.

Algoritmus bývá inicializován

$
\begin{equation}
    \begin{split}
        \textbf{P}_0 &= \delta\textbf{L} \\
        \textbf{w}_0 &= \left[ 1, 0,\dots,0 \right]^T
    \end{split}
\end{equation}
$

## **Adaptivní filtry ve frekvenční oblasti**

Prakticky: signály transformujeme okénkovou DFT(STFT - Short-Time Fourier Transform)

$
\begin{equation}
    X(\theta, t) = \sum_{n=mR}^{mR+N-1} o(n-mR)x(n)e^{-i2\pi(n-mR)\theta / N}
\end{equation}
$

kde $N$ je délka okénka, $R$ je krok posunutí sousedních okének a $o(n)$ je okénkovací funkce.

K parametru $\theta$ (frekvence, index frekvence) přibude $t$ (čas, index časového okénka)

Více na [Přednáška Prof. Nobutaka Ono]

**Příklad**
Minimalizujeme

$
\begin{equation}
    J(W(\theta),t) = \left| D(\theta,t) - \overline{W(\theta,t)}X(\theta,t) \right|^2
\end{equation}
$

Krok adaptivního LMS filtru je 

$
\begin{equation}
    W(\theta,t+1) = W(\theta,t) + \mu X(\theta,t)\text{e}(\theta,t)
\end{equation}
$

kde $\text{e}(\theta,t) = D(\theta,t) - \overline{W(\theta,t)}X(\theta,t)$

Adaptace filtru probíhá pro každou frekvenci nezávisle - paralelně